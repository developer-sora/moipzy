import { NextRequest, NextResponse } from "next/server";
import { OpenAI } from "openai";

const openai = new OpenAI({
  apiKey: process.env["OPENAI_API_KEY"],
});

const mockText = `â˜ï¸ **ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ìš”ì•½**  
ì˜¤ëŠ˜ì€ í•˜ë£¨ ì¢…ì¼ ë¹„ê°€ ë‚´ë¦¬ëŠ” ë‚ ì”¨ì…ë‹ˆë‹¤. ê¸°ì˜¨ì€ 25ë„ë¡œ, ì•„ì¹¨ë¶€í„° ì €ë…ê¹Œì§€ í° ê¸°ì˜¨ ë³€í™” ì—†ì´ ë‹¤ì†Œ ìŠµí•œ ì´ˆì—¬ë¦„ ë‚ ì”¨ì˜ˆìš”.

ğŸ§¥ **ì¶”ì²œ ì˜·ì°¨ë¦¼**

- ë¼ì´íŠ¸ ë°©ìˆ˜ ì¬í‚· or ì–‡ì€ íŠ¸ë Œì¹˜ì½”íŠ¸  
- ë°˜íŒ” ë˜ëŠ” ì–‡ì€ ê¸´íŒ” í‹°ì…”ì¸   
- ê°€ë²¼ìš´ íŒ¬ì¸  or ìŠ¬ë™ìŠ¤
- ë°©ìˆ˜ë˜ëŠ” ìŠ¤ë‹ˆì»¤ì¦ˆ or ìƒŒë“¤
- ë°ì€ ìƒ‰ìƒì˜ ìš°ì‚° (ì ‘ì´ì‹ ìš°ì‚° ì¶”ì²œ!)  
- ë¯¸ë‹ˆ í¬ë¡œìŠ¤ë°± & ë°©ìˆ˜ íŒŒìš°ì¹˜

ğŸ’¡ **íŒ & ë§ˆë¬´ë¦¬ ë©˜íŠ¸**  
ì˜¤ëŠ˜ì€ ë¹„ ë•Œë¬¸ì— ê³µê¸° ì¤‘ ìŠµë„ê°€ ë†’ì•„ ì¡°ê¸ˆ ë‹µë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ë°©ìˆ˜ ì•„ìš°í„°ì™€ ì‚°ëœ»í•œ í¬ì¸íŠ¸ ì•„ì´í…œ(ì»¬ëŸ¬ ì–‘ë§, ë°ì€ ìš°ì‚° ë“±)ìœ¼ë¡œ ìŠ¤íƒ€ì¼ë„ ì‚´ë¦¬ê³ , ì¾Œì í•¨ë„ ì±™ê²¨ë³´ì„¸ìš”!  
ë¹„ ë§ì§€ ì•Šë„ë¡ ìš°ì‚° ê¼­ ì±™ê¸°ê³ , ì –ì€ ì‹ ë°œì€ ë°”ë¡œ ë§ë ¤ì£¼ì„¸ìš”. ì‘ì€ ì»¬ëŸ¬ í¬ì¸íŠ¸ í•˜ë‚˜ë¡œ íë¦° ë‚ ì”¨ë„ ê¸°ë¶„ ì¢‹ê²Œ ì‹œì‘í•˜ì‹œê¸¸ ì‘ì›í•©ë‹ˆë‹¤.  
ì¦ê±°ìš´ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜”ğŸŒˆ 
ì˜¤ëŠ˜ì€ ë¹„ ë•Œë¬¸ì— ê³µê¸° ì¤‘ ìŠµë„ê°€ ë†’ì•„ ì¡°ê¸ˆ ë‹µë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ë°©ìˆ˜ ì•„ìš°í„°ì™€ ì‚°ëœ»í•œ í¬ì¸íŠ¸ ì•„ì´í…œ(ì»¬ëŸ¬ ì–‘ë§, ë°ì€ ìš°ì‚° ë“±)ìœ¼ë¡œ ìŠ¤íƒ€ì¼ë„ ì‚´ë¦¬ê³ , ì¾Œì í•¨ë„ ì±™ê²¨ë³´ì„¸ìš”!  
ë¹„ ë§ì§€ ì•Šë„ë¡ ìš°ì‚° ê¼­ ì±™ê¸°ê³ , ì –ì€ ì‹ ë°œì€ ë°”ë¡œ ë§ë ¤ì£¼ì„¸ìš”. ì‘ì€ ì»¬ëŸ¬ í¬ì¸íŠ¸ í•˜ë‚˜ë¡œ íë¦° ë‚ ì”¨ë„ ê¸°ë¶„ ì¢‹ê²Œ ì‹œì‘í•˜ì‹œê¸¸ ì‘ì›í•©ë‹ˆë‹¤.  
ì¦ê±°ìš´ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜”ğŸŒˆ 
`;

export async function POST(req: NextRequest) {
  const { messages } = await req.json();

  try {
    // const stream = await openai.chat.completions.create({
    //   model: "gpt-4.1",
    //   messages,
    //   stream: true,
    // });

    const encoder = new TextEncoder();

    const readable = new ReadableStream({
      async start(controller) {
        for (const char of mockText) {
          controller.enqueue(encoder.encode(char));
          await new Promise((r) => setTimeout(r, 15)); // ê¸€ìë‹¹ 15ms ë”œë ˆì´
        }
        controller.close();
      },
    });

    // const readable = new ReadableStream({
    //   async start(controller) {
    //     for await (const chunk of stream) {
    //       const text = chunk.choices[0]?.delta?.content;
    //       if (text) {
    //         controller.enqueue(encoder.encode(text));
    //       }
    //     }
    //     controller.close();
    //   },
    // });

    return new Response(readable, {
      headers: {
        "Content-Type": "text/event-stream",
      },
    });
  } catch (error) {
    console.error("OpenAI Error:", error);
    return NextResponse.json({ error: "OpenAI ìš”ì²­ ì‹¤íŒ¨" }, { status: 500 });
  }
}
